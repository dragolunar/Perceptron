import math
import random
import datetime
import enum


class Function(enum.Enum):

    NONE                = 0
    THRESHOLD           = 1
    SIGMOID             = 2
    HYPERBOLIC_TANGENT  = 3


class Perceptron:

    def __init__(self, dimension, function=1):
        
        self.inputVector = []
        self.weightsVector = []
        self.activationFunction = 0

        random.seed(datetime.datetime.now())
        for i in range(dimension):
            self.weightsVector.append(random.random() - 0.5)
        self.inputVector = [None]*dimension
        self.activationFunction = function
        
    def setWeights(self, weightsVector):
        
        self.weightsVector = weightsVector

    def setSample(self, inputVector):
        
        self.inputVector = inputVector
        
    def calculateNet(self):

        action = 0.0
        for i in range(len(self.inputVector)):
            action += self.inputVector[i]*self.weightsVector[i]

        if (self.activationFunction == Function.THRESHOLD):
            if (action >= 0.0):
                action = 1
            else:
                action = 0
        elif (self.activationFunction == Function.SIGMOID):
            action = 1.0/(1.0 + math.exp(-action))
        elif (self.activationFunction == Function.HYPERBOLIC_TANGENT):
            action = (math.exp(2*action) - 1)/(math.exp(2*action) + 1)
        else:
            print('set 1-3 to activation function as THRESHOLD, SIGMOID, or HYPERBOLIC_TANGENT')
            exit()

        return action

    def adjustWeights(self, teachingStep, output, target):

        for i in range(len(self.weightsVector)):
            # error correction learning rule
            self.weightsVector[i] += teachingStep*(target - output)*self.inputVector[i]

    def recall(self, inputVector):
        
        self.setSample(inputVector)
        return self.calculateNet()


if __name__ == "__main__":
    
    def scaling(x):
        return (x - 0)/(255 - 0)

    CLASS_RED = 0
    CLASS_BLUE = 1
    DIMENSION = 3
    LEASTMEANSQUAREERROR    = 0.001
    TEACHINGSTEP            = 0.01

    samples = [
        [0, 0, 255, CLASS_BLUE],
        [0, 0, 192, CLASS_BLUE],
        [243, 80, 59, CLASS_RED],
        [255, 0, 77, CLASS_RED],
        [77, 93, 190, CLASS_BLUE],
        [255, 98, 89, CLASS_RED],
        [208, 0, 49, CLASS_RED],
        [67, 15, 210, CLASS_BLUE],
        [82, 117, 174, CLASS_BLUE],
        [168, 42, 89, CLASS_RED],
        [248, 80, 68, CLASS_RED],
        [128, 80, 255, CLASS_BLUE],
        [228, 105, 116, CLASS_RED],
    ]

    neuron = Perceptron(DIMENSION, Function.SIGMOID)
    
    mse = 999
    epochs = 0

    while (math.fabs(mse - LEASTMEANSQUAREERROR) > 0.0001):
        mse = 0
        error = 0

        for sample in samples:
            temp = []
            for i in range(DIMENSION):
                temp.append(scaling(sample[i]))
            neuron.setSample(temp)

            output = neuron.calculateNet()
            error += math.fabs(sample[DIMENSION] - output)
            neuron.adjustWeights(TEACHINGSTEP, output, sample[DIMENSION])

        mse = error/len(samples)
        print('The mean square error of %d epoch is %.4f' % (epochs, mse))
        epochs += 1
